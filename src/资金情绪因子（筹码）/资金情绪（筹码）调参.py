import pandas as pd
import numpy as np
import itertools
import time
import os
import csv
from typing import Dict, List, Any, Tuple

# å°è¯•å¯¼å…¥è¿›åº¦æ¡åº“ï¼Œæ²¡æœ‰ä¹Ÿä¸å½±å“è¿è¡Œ
try:
    from tqdm import tqdm
except ImportError:
    def tqdm(iterator, **kwargs):
        return iterator

import warnings

warnings.filterwarnings('ignore')

# ----------------------------------------------------------------------
# ğŸ“Œ 1. é…ç½®åŒºåŸŸï¼šç›®æ ‡å…¬å¼ä¸å‚æ•°èŒƒå›´
# ----------------------------------------------------------------------
FILE_PATH = r"C:\Users\86178\Desktop\èµ„é‡‘å¤§ä¸­å°å› å­.xlsx"
RESULT_FILE = "grid_search_final_result.csv"  # ç»“æœä¿å­˜æ–‡ä»¶


# === ç›®æ ‡å‡½æ•°å®šä¹‰ (ä¸å˜) ===
def calculate_score(excess: float, sharpe: float, max_dd: float) -> float:
    """
    ç›®æ ‡ï¼š(è¶…é¢ * å¤æ™®) / |å›æ’¤|
    """
    if excess <= 0: return -999.0
    abs_dd = abs(max_dd)
    if abs_dd < 0.001: abs_dd = 0.001
    score = (excess * sharpe) / abs_dd
    return score


# === å‚æ•°æ±  (ä¸å˜) ===
PARAM_GRID = {
    'z_window': np.arange(20, 85, 1).tolist(),
    'factor_smooth': [5, 10, 15, 20],
    'neutral_th': np.round(np.arange(0.30, 0.60, 0.1), 2).tolist(),
    'max_th': np.round(np.arange(2.0, 4.1, 0.5), 2).tolist(),
    'req_days': [1, 2, 3, 5],
    'ma_window': [10, 20, 30]
}


# ----------------------------------------------------------------------
# ğŸ“Œ 2. æ•°æ®é¢„å¤„ç†ä¸åŠ é€Ÿç¼“å­˜ (å·²ä¿®æ”¹ï¼šæ–°å¢æ•°æ®åˆ’åˆ†)
# ----------------------------------------------------------------------

# Helper function to process the DataFrame slice
def process_data_slice(df_slice, param_grid):
    """
    å¤„ç† DataFrame åˆ‡ç‰‡ï¼Œç”Ÿæˆ data_dict, ma_cache, factor_cacheã€‚
    """
    # åŸºç¡€æ•°æ®è½¬ Numpy
    data_dict = {
        'p1': df_slice['close_price1'].values,
        'p2': df_slice['close_price2'].values,
        'r1': df_slice['index_return1'].values,
        'r2': df_slice['index_return2'].values,
        'rf1': ((df_slice['buy_value_xl1'] + df_slice['buy_value_l1']) - (
                    df_slice['sell_value_xl1'] + df_slice['sell_value_l1'])).values,
        'rf2': ((df_slice['buy_value_xl2'] + df_slice['buy_value_l2']) - (
                    df_slice['sell_value_xl2'] + df_slice['sell_value_l2'])).values
    }

    # 1. é¢„è®¡ç®—æ‰€æœ‰å‡çº¿ (MA)
    ma_cache = {}
    for w in param_grid['ma_window']:
        # ä½¿ç”¨ min_periods=1 é¿å…å¤§é‡ NaN
        ma_cache[f'ma1_{w}'] = df_slice['close_price1'].rolling(w, min_periods=1).mean().values
        ma_cache[f'ma2_{w}'] = df_slice['close_price2'].rolling(w, min_periods=1).mean().values

    # 2. é¢„è®¡ç®—æ‰€æœ‰å› å­ç»„åˆ (Z-Score)
    factor_cache = {}

    def calc_raw_ratio(suffix):
        net = (df_slice[f'buy_value_xl{suffix}'] + df_slice[f'buy_value_l{suffix}']) - \
              (df_slice[f'sell_value_xl{suffix}'] + df_slice[f'sell_value_l{suffix}']) - \
              (df_slice[f'buy_value_s{suffix}'] - df_slice[f'sell_value_s{suffix}'])
        mkt = df_slice[f'free_float_mktval{suffix}']
        return net / mkt

    ratio1 = calc_raw_ratio('1')
    ratio2 = calc_raw_ratio('2')

    for fs, zw in itertools.product(param_grid['factor_smooth'], param_grid['z_window']):
        r1_smooth = ratio1.rolling(fs, min_periods=1).sum()
        r2_smooth = ratio2.rolling(fs, min_periods=1).sum()

        # Z-Score
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ min_periods=1 æ¥é¿å…åˆå§‹çš„å¤§é‡ NaN å½±å“åç»­æ•°æ®
        z1 = (r1_smooth - r1_smooth.rolling(zw, min_periods=1).mean()) / r1_smooth.rolling(zw, min_periods=1).std()
        z2 = (r2_smooth - r2_smooth.rolling(zw, min_periods=1).mean()) / r2_smooth.rolling(zw, min_periods=1).std()

        factor_cache[f'{fs}_{zw}'] = (z1 - z2).values

    return data_dict, ma_cache, factor_cache


def prepare_data_and_cache_split(file_path: str, param_grid: Dict[str, List[Any]], split_ratio: float = 0.7) -> Tuple[
    Tuple, Tuple]:
    """
    è¯»å–æ•°æ®ï¼ŒæŒ‰æ—¶é—´è½´ 7:3 åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶å¯¹ä¸¤è€…åˆ†åˆ«è¿›è¡Œé¢„è®¡ç®—ã€‚
    """
    if not os.path.exists(file_path):
        print(f"ğŸš¨ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶è·¯å¾„ {file_path}")
        return (None, None, None), (None, None, None)

    print(f"æ­£åœ¨è¯»å–æ•°æ®å¹¶è¿›è¡Œ 7:3 åˆ’åˆ†åŠ é€Ÿ: {file_path}")
    df = pd.read_excel(file_path)
    df['TradingDay'] = pd.to_datetime(df['TradingDay'])
    df = df.sort_values('TradingDay').reset_index(drop=True)

    # åˆ’åˆ†ç´¢å¼•
    n = len(df)
    split_index = int(n * split_ratio)

    df_train = df.iloc[:split_index].copy().reset_index(drop=True)
    df_test = df.iloc[split_index:].copy().reset_index(drop=True)

    print(f"åŸå§‹æ•°æ®æ€»é•¿åº¦: {n} å¤©")
    print(
        f"ğŸ”‘ è®­ç»ƒé›†é•¿åº¦ ({split_ratio * 100:.0f}%): {len(df_train)} å¤© ({df_train['TradingDay'].iloc[0].date()} è‡³ {df_train['TradingDay'].iloc[-1].date()})")
    print(
        f"ğŸ”’ æµ‹è¯•é›†é•¿åº¦ ({(1 - split_ratio) * 100:.0f}%): {len(df_test)} å¤© ({df_test['TradingDay'].iloc[0].date()} è‡³ {df_test['TradingDay'].iloc[-1].date()})")

    # å¯¹è®­ç»ƒé›†è¿›è¡Œé¢„è®¡ç®—
    train_data, train_ma, train_factor = process_data_slice(df_train, param_grid)
    print("--- è®­ç»ƒé›†é¢„è®¡ç®—å®Œæˆ ---")

    # å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„è®¡ç®—
    test_data, test_ma, test_factor = process_data_slice(df_test, param_grid)
    print("--- æµ‹è¯•é›†é¢„è®¡ç®—å®Œæˆ ---")

    return (train_data, train_ma, train_factor), (test_data, test_ma, test_factor)


# ----------------------------------------------------------------------
# ğŸ“Œ 3. æé€Ÿå›æµ‹å†…æ ¸ (ä¸å˜)
# ----------------------------------------------------------------------
# ä¿æŒ fast_backtest å‡½æ•°ä¸å˜ï¼Œå› ä¸ºå®ƒå¤„ç†çš„æ˜¯ä¼ å…¥çš„ data, ma_cache, factor_cache ç»“æ„

def fast_backtest(params: Dict[str, float], data: Dict[str, np.ndarray], ma_cache: Dict[str, np.ndarray],
                  factor_cache: Dict[str, np.ndarray]) -> Tuple[float, float, float]:
    # è§£åŒ…å‚æ•°
    zw = int(params['z_window'])
    fs = int(params['factor_smooth'])
    nt = params['neutral_th']
    mt = params['max_th']
    rd = int(params['req_days'])
    mw = int(params['ma_window'])

    # ä»ç¼“å­˜è·å–æ•°ç»„
    spread = factor_cache[f'{fs}_{zw}']
    ma1 = ma_cache[f'ma1_{mw}']
    ma2 = ma_cache[f'ma2_{mw}']

    p1 = data['p1']
    p2 = data['p2']
    rf1 = data['rf1']
    rf2 = data['rf2']
    r1 = data['r1']
    r2 = data['r2']

    n = len(spread)
    target_weights = np.full(n, 0.5)

    # çŠ¶æ€å˜é‡ï¼ˆéœ€è¦ä¸²è¡Œè¿­ä»£ï¼‰
    last_locked = 0.5
    cb = 0  # consecutive bull
    cbr = 0  # consecutive bear
    range_width = mt - nt

    # --- æ ¸å¿ƒå¾ªç¯ ---
    for i in range(n):
        s = spread[i]

        if np.isnan(s) or np.isnan(ma1[i]):
            target_weights[i] = last_locked
            continue

        # è®¡æ•°å™¨
        if s > nt:
            cb += 1;
            cbr = 0
        elif s < -nt:
            cbr += 1;
            cb = 0
        else:
            cb = 0;
            cbr = 0

        curr = last_locked

        # å†³ç­–
        if abs(s) <= nt:
            curr = 0.5
            last_locked = 0.5
        elif s > nt:  # Index1 å¼ºåŠ¿
            if (cb >= rd) and (p1[i] > ma1[i]) and (rf1[i] > 0):
                raw = 0.5 + 0.5 * ((s - nt) / range_width)
                if raw > 1.0: raw = 1.0
                if last_locked < 0.5:
                    curr = raw
                else:
                    curr = raw if raw > last_locked else last_locked
                last_locked = curr
        else:  # s < -ntï¼ŒIndex2 å¼ºåŠ¿
            if (cbr >= rd) and (p2[i] > ma2[i]) and (rf2[i] > 0):
                raw = 0.5 - 0.5 * ((abs(s) - nt) / range_width)
                if raw < 0.0: raw = 0.0
                if last_locked > 0.5:
                    curr = raw
                else:
                    curr = raw if raw < last_locked else last_locked
                last_locked = curr

        target_weights[i] = curr

    # ä¿¡å·æ»åä¸€å¤©
    targets = np.roll(target_weights, 1);
    targets[0] = 0.5

    # --- å¿«é€Ÿç®—å‡€å€¼ (è€ƒè™‘äº¤æ˜“æˆæœ¬) ---
    nav_s = np.zeros(n)
    nav_b = np.ones(n)

    # åŸºå‡†å‡€å€¼
    b1, b2 = 0.5, 0.5
    for i in range(n):
        b1 *= (1 + r1[i])
        b2 *= (1 + r2[i])
        nav_b[i] = b1 + b2

    # ç­–ç•¥å‡€å€¼
    h1, h2 = 0.5, 0.5
    prev_w = 0.5
    cost_rate = 0.0001

    for i in range(n):
        w = targets[i]
        rr1, rr2 = r1[i], r2[i]

        # è°ƒä»“
        if abs(w - prev_w) > 0.001:
            tot = h1 + h2
            t1 = tot * w
            t2 = tot * (1 - w)
            c = (abs(t1 - h1) + abs(t2 - h2)) * cost_rate
            ntot = tot - c
            h1 = ntot * w
            h2 = ntot * (1 - w)
            prev_w = w

        # æ¯æ—¥æ¶¨è·Œå¹…æ›´æ–°
        h1 *= (1 + rr1)
        h2 *= (1 + rr2)
        nav_s[i] = h1 + h2

    # --- æŒ‡æ ‡è®¡ç®— ---
    total_ret = nav_s[-1] - 1
    bench_ret = nav_b[-1] - 1
    excess = total_ret - bench_ret

    # å¤æ™®æ¯”ç‡
    pct = np.diff(nav_s) / nav_s[:-1]
    annual_rf = 0.02
    daily_rf = annual_rf / 250
    if len(pct) < 2 or np.std(pct) < 1e-6:
        sharpe = 0
    else:
        sharpe = (np.mean(pct) - daily_rf) / np.std(pct) * np.sqrt(250)

    # æœ€å¤§å›æ’¤
    cummax = np.maximum.accumulate(nav_s)
    dd = nav_s / cummax - 1
    max_dd = np.min(dd)

    return excess, sharpe, max_dd


# ----------------------------------------------------------------------
# ğŸ“Œ 4. ä¸»ç¨‹åºï¼šåœ¨è®­ç»ƒé›†ä¸Šæœç´¢ï¼Œåœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯ (å·²ä¿®æ”¹)
# ----------------------------------------------------------------------
def main():
    # 1. å‡†å¤‡æ•°æ®ï¼šè·å– 70% è®­ç»ƒé›†å’Œ 30% æµ‹è¯•é›†
    (train_data, train_ma, train_factor), (test_data, test_ma, test_factor) = prepare_data_and_cache_split(FILE_PATH,
                                                                                                           PARAM_GRID)

    if train_data is None: return

    # 2. ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
    keys = list(PARAM_GRID.keys())
    valid_combinations = []
    param_values = [PARAM_GRID[k] for k in keys]

    # è¿‡æ»¤æ‰ max_th <= neutral_th çš„æ— æ•ˆç»„åˆ
    for values in itertools.product(*param_values):
        params = dict(zip(keys, values))
        if params['max_th'] > params['neutral_th']:
            valid_combinations.append(params)

    total_combs = len(valid_combinations)
    results_to_write: List[List[Any]] = []

    print(f"\nğŸš€ å¼€å§‹åœ¨ã€è®­ç»ƒé›†ã€‘ä¸Šè¿›è¡Œç½‘æ ¼æœç´¢ä¼˜åŒ–...")
    print(f"æ€»è®¡æœ‰æ•ˆç»„åˆæ•°: {total_combs}")
    print("-" * 50)

    # 3. åœ¨ã€è®­ç»ƒé›†ã€‘ä¸Šå¾ªç¯å›æµ‹å’Œä¼˜åŒ–
    start_time = time.time()
    best_train_score = -999.0
    best_params = None

    for i, params in tqdm(enumerate(valid_combinations), total=total_combs, unit="comb"):

        processed_params = {k: float(v) for k, v in params.items()}

        # âš ï¸ ä»…åœ¨ã€è®­ç»ƒé›†ã€‘ä¸Šæ‰§è¡Œå›æµ‹
        excess, sharpe, max_dd = fast_backtest(processed_params, train_data, train_ma, train_factor)

        # è®¡ç®—å¾—åˆ†
        score = calculate_score(excess, sharpe, max_dd)

        # è®°å½•æœ€ä¼˜å‚æ•°
        if score > best_train_score:
            best_train_score = score
            best_params = params

        # æ”¶é›†ç»“æœè¡Œ
        row_values = list(params.values())
        row = row_values + [excess, sharpe, max_dd, score]
        results_to_write.append(row)

    end_time = time.time()
    duration = end_time - start_time

    # 4. ä¸€æ¬¡æ€§å†™å…¥ç½‘æ ¼æœç´¢ç»“æœ
    print(f"\næ­£åœ¨å†™å…¥ {len(results_to_write)} æ¡ã€è®­ç»ƒé›†ã€‘æœç´¢ç»“æœåˆ°æ–‡ä»¶...")
    headers = keys + ['Excess', 'Sharpe', 'MaxDD', 'Score']

    with open(RESULT_FILE, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        writer.writerows(results_to_write)

    print(f"\nâœ… è®­ç»ƒé›†æœç´¢å®Œæˆï¼è€—æ—¶: {duration / 3600:.2f} å°æ—¶ ({duration:.2f} ç§’)")
    print("-" * 50)

    # 5. åœ¨ã€æµ‹è¯•é›†ã€‘ä¸Šè¿›è¡ŒéªŒè¯
    if best_params is not None and test_data[0] is not None:
        print("\nğŸ† å¼€å§‹åœ¨ã€æµ‹è¯•é›†ã€‘ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°...")

        processed_best_params = {k: float(v) for k, v in best_params.items()}

        # âš ï¸ åœ¨ã€æµ‹è¯•é›†ã€‘ä¸Šæ‰§è¡Œå•æ¬¡å›æµ‹
        test_excess, test_sharpe, test_max_dd = fast_backtest(processed_best_params, test_data, test_ma, test_factor)
        test_score = calculate_score(test_excess, test_sharpe, test_max_dd)

        print("\nâ­â­â­ éªŒè¯ç»“æœ â­â­â­")
        print(f"é€‰å®šæœ€ä¼˜å‚æ•° (åŸºäºè®­ç»ƒé›† Score={best_train_score:.4f}): {best_params}")
        print(f"ã€æµ‹è¯•é›†ã€‘ç»©æ•ˆ (Score={test_score:.4f}):")
        print(f"  - è¶…é¢æ”¶ç›Š(Excess): {test_excess:.2%}")
        print(f"  - å¤æ™®æ¯”ç‡(Sharpe): {test_sharpe:.2f}")
        print(f"  - æœ€å¤§å›æ’¤(MaxDD): {test_max_dd:.2%}")

        # è¯„ä¼°æ³›åŒ–èƒ½åŠ›
        if test_score > 0 and test_excess > 0:
            print("\nğŸ‰ ç»“è®ºï¼šæµ‹è¯•é›†è¡¨ç°è‰¯å¥½ï¼Œç­–ç•¥æ³›åŒ–èƒ½åŠ›å¼ºï¼")
        else:
            print("\nâš ï¸ ç»“è®ºï¼šæµ‹è¯•é›†è¡¨ç°ä¸ä½³ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦æ‹Ÿåˆ (Overfitting)ï¼")
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆå‚æ•°æˆ–æµ‹è¯•é›†æ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡éªŒè¯ã€‚")


# ----------------------------------------------------------------------
# ğŸ“Œ 5. ç»“æœåˆ†æ (å·²ä¿®æ”¹ï¼šåªåˆ†æè®­ç»ƒé›†ç»“æœ)
# ----------------------------------------------------------------------
def analyze_results():
    if not os.path.exists(RESULT_FILE):
        print("æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶")
        return

    print(f"\næ­£åœ¨åˆ†æã€è®­ç»ƒé›†ã€‘ç½‘æ ¼æœç´¢æœ€ä½³ç»“æœ...")
    df = pd.read_csv(RESULT_FILE)
    df = df[df['Score'] > 0]

    if df.empty:
        print("æ²¡æœ‰æ‰¾åˆ° Score å¤§äº 0 çš„æœ‰æ•ˆå‚æ•°ç»„åˆã€‚")
        return

    df = df.sort_values(by='Score', ascending=False).reset_index(drop=True)

    print("ğŸ† Top 5 å‚æ•°ç»„åˆ (è®­ç»ƒé›†)")
    print(df.head(5).to_string(index=False))


if __name__ == "__main__":
    main()
    # è·‘å®Œåè‡ªåŠ¨åˆ†æè®­ç»ƒé›†ç»“æœ
    analyze_results()